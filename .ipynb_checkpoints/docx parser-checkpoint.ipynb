{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx.api import Document\n",
    "from docx.oxml.table import CT_Tbl\n",
    "from docx.oxml.text.paragraph import CT_P\n",
    "from docx.table import _Cell, Table\n",
    "from docx.text.paragraph import Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the docx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to directory containing docx files\n",
    "docx_dir = './docx/'\n",
    "\n",
    "docx_files = glob.glob(docx_dir + '*.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./docx\\\\Bagerhat.docx'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docx_files[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_block_items(parent):\n",
    "    \"\"\"\n",
    "    Take a Document object and yields all paragraph and table objects\n",
    "    in the order inside the docx file.\n",
    "    \n",
    "    Input:\n",
    "        - parent (docx.api.Document object)\n",
    "        \n",
    "    Source: https://stackoverflow.com/questions/42093013/processing-objects-in-order-in-docx\n",
    "    \"\"\"\n",
    "    parent_elm = parent.element.body\n",
    "\n",
    "    for child in parent_elm.iterchildren():\n",
    "        if isinstance(child, CT_P):\n",
    "            yield Paragraph(child, parent)\n",
    "        elif isinstance(child, CT_Tbl):\n",
    "            yield Table(child, parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the docx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the docx contents will go in this\n",
    "all_contents = []\n",
    "\n",
    "document = Document(docx_files[0])\n",
    "\n",
    "# iterate through each block of the docx file\n",
    "for block_item in iter_block_items(document):\n",
    "    \n",
    "    # check if the block is a paragraph object\n",
    "    if isinstance(block_item, Paragraph):\n",
    "        inner_text = block_item.text\n",
    "        \n",
    "        # check if inner text is empty\n",
    "        if inner_text != '':\n",
    "            try:\n",
    "                # print(\"\\nPARA:\", block_item.style.name, inner_text)\n",
    "                \n",
    "                # store the parapragh info in a nested array\n",
    "                all_contents.append([\n",
    "                    \"p\",\n",
    "                    block_item.style.name,\n",
    "                    inner_text\n",
    "                ])\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # check if the block is a table object\n",
    "    elif isinstance(block_item, Table):\n",
    "        # print(\"\\nTABLE:\")\n",
    "        \n",
    "        inner_values = []\n",
    "        #iterate through each row and the cell values\n",
    "        for row in block_item.rows:\n",
    "            inner_values.append([cell.text for cell in row.cells])\n",
    "\n",
    "        # store the values in a nested array\n",
    "        all_contents.append([\n",
    "            \"t\",\n",
    "            inner_values\n",
    "        ])\n",
    "    else:\n",
    "        print(\"\\nUNKNOWN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of paraghs and tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to read the tables and paragraphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [a for a in all_contents if a[0] == 't']\n",
    "paraghs = [a for a in all_contents if a[0] == 'p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t',\n",
      " [['Upazila', 'Muslim', 'Hindu', 'Buddhist', 'Christian', 'Others', 'Total'],\n",
      "  ['Bagerhat Sadar', '219207', '46547', '561', '4', '70', '266389'],\n",
      "  ['Chitalmari', '92739', '46003', '58', '2', '8', '138810'],\n",
      "  ['Fakirhat', '104951', '32628', '57', '0', '153', '137789'],\n",
      "  ['Kachua', '78645', '18347', '19', '0', '0', '97011'],\n",
      "  ['Mollahat', '104335', '26302', '89', '0', '152', '130878'],\n",
      "  ['Mongla', '102298', '29426', '4837', '21', '6', '136588'],\n",
      "  ['Morrelgonj', '263332', '31136', '34', '2', '72', '294576'],\n",
      "  ['Rampal', '123250', '31253', '448', '10', '4', '154965'],\n",
      "  ['Sarankhola', '109836', '9232', '12', '4', '0', '119084'],\n",
      "  ['Total', '1198593', '270874', '6115', '43', '465', '1476090']]]\n"
     ]
    }
   ],
   "source": [
    "pprint(tables[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p',\n",
      " 'Body Text',\n",
      " 'The population and housing census is the unique source of reliable and '\n",
      " 'comprehensive data about the size of the population of the country, major '\n",
      " 'socio-economic and socio-demographic characteristics.']\n"
     ]
    }
   ],
   "source": [
    "pprint(paraghs[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pickled.\n"
     ]
    }
   ],
   "source": [
    "with open(\"./pickles/Bagerhat.pkl\", \"wb\") as f:\n",
    "        pickle.dump(all_contents, f)\n",
    "        print(\"Successfully pickled.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
